{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# src_path = os.path.realpath(os.path.join(os.path.dirname(__file__), '../../src'))\n",
    "# sys.path.append(src_path)\n",
    "src_path = os.path.realpath(os.path.join(os.getcwd(), './src'))\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import random\n",
    "from utilFuncs import *\n",
    "import matplotlib.patches as mpatches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 7\n",
    "unitCellName = 'C12'\n",
    "numberOfDataFiles = 2 # seed 0-1 (2), just seed0 (1)\n",
    "# make sure analysis is done on the same geometry and compression ratio \n",
    "heightLattice = 12.7 # mm\n",
    "compression = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveLoc = unitCellName + 'NN' + str(p) + 'var/'\n",
    "filenames = [] # Initialize an empty list to store the generated filenames\n",
    "\n",
    "for seed_num in range(numberOfDataFiles): # range(2) will generate 0, 1\n",
    "    filename = (SaveLoc + 'abaqusComp' + str(compression) +\n",
    "                unitCellName + 'LHS_' + str(p) + 'var_seedNum' + str(seed_num))\n",
    "    filenames.append(filename)\n",
    "\n",
    "if p==2: # uniform data replace filenames\n",
    "    filenames = [SaveLoc+'abaqusComp'+str(compression)+unitCellName+'uniform_'+str(p)+'var_seedNum0']\n",
    "\n",
    "\n",
    "compressionRatio = compression*0.01\n",
    "maxDispUz = heightLattice*compressionRatio # mm\n",
    "\n",
    "ctr = \".txt\"\n",
    "R = np.array([])\n",
    "U = np.array([])\n",
    "F = np.array([])\n",
    "analysisState = np.array([])\n",
    "\n",
    "for filename in filenames:\n",
    "    filename = filename+ctr\n",
    "    \n",
    "    DesVarTemp, UTemp, FTemp, analysisStateTemp = extract_ABQ_values(filename,torch.linspace(0,1,11)*maxDispUz)\n",
    "    if R.size == 0:\n",
    "        R = DesVarTemp\n",
    "        U = UTemp\n",
    "        F = FTemp\n",
    "        analysisState = analysisStateTemp\n",
    "    else:\n",
    "        R = np.concatenate((R, DesVarTemp))\n",
    "        U = np.concatenate((U, UTemp))\n",
    "        F = np.concatenate((F, FTemp))\n",
    "        analysisState = np.concatenate((analysisState, analysisStateTemp))\n",
    "\n",
    "U = U/np.max(U)\n",
    "\n",
    "for i in range(len(analysisState)):\n",
    "    if analysisState[i] == 1:\n",
    "        t = U[i,:]\n",
    "        break;\n",
    "mask = ((np.abs(U - t[np.newaxis,:]))<=1e-6)*1.0\n",
    "\n",
    "\n",
    "# take out the failed or keep solutions\n",
    "includeFailed = True\n",
    "maskinputDiv = mask[analysisState == 0,:]\n",
    "\n",
    "if includeFailed:\n",
    "    maskinput = mask[analysisState <= 1,:]\n",
    "    Uinput = U[analysisState <= 1,:]\n",
    "    NNinput = R[analysisState <= 1,:]\n",
    "    NNoutput= F[analysisState <= 1,:]\n",
    "else:\n",
    "    maskinput = mask[analysisState == 1,:]\n",
    "    Uinput = U[analysisState == 1,:]\n",
    "    NNinput = R[analysisState == 1,:]\n",
    "    NNoutput= F[analysisState == 1,:]\n",
    "    \n",
    "NNinputDiv = R[analysisState == 0,:]\n",
    "NNoutputDiv = F[analysisState == 0,:]\n",
    "\n",
    "    \n",
    "inputSize = NNinput.shape[1]\n",
    "outputSize = NNoutput.shape[1]\n",
    "\n",
    "dataInput = np.concatenate((NNinput,maskinput),axis=1)\n",
    "dataOutput =  NNoutput.copy()\n",
    "\n",
    "# make sure the partial curve has at least half of the data ()\n",
    "sumMask = np.sum(maskinput,axis=1)\n",
    "Num = (sumMask>=0.5*(outputSize-1)) # skip the first 0th size\n",
    "analysisState = sumMask/np.max(sumMask) # change the analysisState such that it shows > half success\n",
    "\n",
    "## remove the less than half success \n",
    "NNinput = np.concatenate((NNinput,maskinput),axis=1)[Num,:]\n",
    "NNoutput = NNoutput[Num,:]\n",
    "NNinputDiv = np.concatenate((NNinputDiv,maskinputDiv),axis=1)\n",
    "\n",
    "success = np.sum(analysisState == 1)\n",
    "partial = np.sum((analysisState >= 0.5) & (analysisState < 1))\n",
    "failure = np.sum(analysisState < 0.5) \n",
    "print(f\"Data shapes: Input (with mask) {NNinput.shape}, Output {NNoutput.shape}\")\n",
    "print(f\"Classification counts: Success={success}, Partial={partial}, Failure={failure}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some force range, and use only that data\n",
    "F_aggregated_Value = np.mean(NNoutput,axis=1)\n",
    "\n",
    "F1,F2 = -np.max(F_aggregated_Value),(np.max(F_aggregated_Value)+1.0)\n",
    "\n",
    "if F2 > 0:\n",
    "    NNinput = NNinput[ (F_aggregated_Value >= F1) & (F_aggregated_Value <= F2) ,:]\n",
    "    NNoutput= NNoutput[(F_aggregated_Value >= F1) & (F_aggregated_Value <= F2),:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test sets\n",
    "train_ratio = 0.8\n",
    "n = int(NNinput.shape[0]/1)  # Get the number of samples (rows)\n",
    "num_train = int(n * train_ratio)  # Calculate number of training samples\n",
    "\n",
    "random.seed(0) \n",
    "# Generate random indices for shuffling\n",
    "indices = list(range(n))\n",
    "random.shuffle(indices)\n",
    "\n",
    "# Split indices into training and testing\n",
    "train_indices = indices[:num_train]\n",
    "test_indices = indices[num_train:]\n",
    "\n",
    "# Use the shuffled indices to select data\n",
    "Rinput_train = NNinput[train_indices,:]\n",
    "Uoutput_train = Uinput[train_indices,:]\n",
    "Foutput_train = NNoutput[train_indices,:]\n",
    "\n",
    "Rinput_test = NNinput[test_indices,:]\n",
    "Uoutput_test = Uinput[test_indices,:]\n",
    "Foutput_test = NNoutput[test_indices,:]\n",
    "\n",
    "inputs_train = Rinput_train # Training Inputs\n",
    "targets_train = Foutput_train # Training Targets\n",
    "\n",
    "inputs_test = Rinput_test # Test Inputs\n",
    "targets_test =  Foutput_test # Test Targets\n",
    "print(f\"Training set shapes: Inputs {inputs_train.shape}, Targets {targets_train.shape}\")\n",
    "print(f\"Testing set shapes: Inputs {inputs_test.shape}, Targets {targets_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAllFDcurves(inputs_train,targets_train,inputs_test,targets_test,lbls=['',''],strAdd= ''):\n",
    "    n = inputs_train.shape[0] + inputs_test.shape[0]\n",
    "    # lbls = [\"Training_set\",\"Validation_set\"]\n",
    "    # lbls = [\"Success\",\"Partial Success\"]\n",
    "    # lbls = [\"Data_1\",\"Data_200\"]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(n+1):\n",
    "        if i < targets_train.shape[0]:\n",
    "            actu = targets_train[i,:].reshape(-1)\n",
    "            uu = np.linspace(0,1,len(actu))\n",
    "            nn = int(inputs_train[i,2::].sum())\n",
    "            if i==0:\n",
    "                plt.plot(uu[0:nn],actu[0:nn],'m-s',label=f'{lbls[0]}')\n",
    "            else:\n",
    "                plt.plot(uu[0:nn],actu[0:nn],'m-s')\n",
    "                \n",
    "        else:\n",
    "            i = i - n\n",
    "            actu = targets_test[i,:].reshape(-1)\n",
    "            uu = np.linspace(0,1,len(actu))\n",
    "            nn = int(inputs_test[i,2::].sum())\n",
    "            if i == -1:\n",
    "                plt.plot(uu[0:nn],actu[0:nn],'b-o',label=f'{lbls[1]}')\n",
    "            else:\n",
    "                plt.plot(uu[0:nn],actu[0:nn],'b-o')        \n",
    "\n",
    "    # # Labels\n",
    "    plt.ylabel('Force in N',fontsize=16)\n",
    "    # plt.ylabel('Normalized Force',fontsize=16)\n",
    "\n",
    "    plt.xlabel('Normalized displacement',fontsize=16)\n",
    "    target = np.concatenate((targets_train,targets_test),axis=0)\n",
    "    # plt.ylim(None,np.max(target)*1.3)\n",
    "    \n",
    "    # Title\n",
    "    titleStr = f'Force Displacement curve data'\n",
    "    titleStr = f'{titleStr} {strAdd}'\n",
    "    plt.title(titleStr,fontsize=18)\n",
    "    plt.legend(fontsize=16,loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def plotFDcurves(ax, inputdata, targetdata, lbl, strAdd, colorshape,addLabel=False):\n",
    "    \"\"\"\n",
    "    Plots force-displacement curves for a single dataset on a given figure.\n",
    "\n",
    "    Args:\n",
    "        fig (matplotlib.figure.Figure): The figure object to plot on.\n",
    "        inputdata (NumPy array): The input data array.\n",
    "        targetdata (NumPy array): The target data array.\n",
    "        lbl (str): The label for this dataset.\n",
    "        strAdd (str): A string to add to the title of the plot.\n",
    "        colorshape (dict): A dictionary specifying the color and marker.\n",
    "                           Expected keys: 'color' and 'marker'.\n",
    "                           Example: {'color': 'm', 'marker': 's'}\n",
    "    \"\"\"\n",
    "    n = inputdata.shape[0]\n",
    "    for i in range(n):\n",
    "        actu = targetdata[i,:].reshape(-1)\n",
    "        uu = np.linspace(0,1,len(actu))\n",
    "        nn = int(inputdata[i,2::].sum())\n",
    "        Color = colorshape['color']\n",
    "        Marker = colorshape['marker']\n",
    "        ax.plot(uu[0:nn], actu[0:nn], marker=Marker, linestyle='-', color=Color, label=lbl if i == 0 else \"\",\n",
    "                linewidth=3,markersize=10)\n",
    "    \n",
    "    if addLabel:\n",
    "        # Labels\n",
    "        ax.set_ylabel('Force in N', fontsize=16)\n",
    "        ax.set_xlabel('Normalized displacement', fontsize=16)\n",
    "    \n",
    "        ax.set_ylim(None, np.max(targetdata) * 1.4 if targetdata.size > 0 else None)\n",
    "    \n",
    "        # Title\n",
    "        titleStr = f'Force Displacement curve data'\n",
    "        titleStr = f'{titleStr} {strAdd}'\n",
    "        ax.set_title(titleStr, fontsize=18)\n",
    "        # ax.legend(fontsize=16, loc='upper left')\n",
    "    # else:\n",
    "    #     ax.set_xticklabels([])\n",
    "    #     ax.set_yticklabels([])\n",
    "        \n",
    "    ax.legend(fontsize=16, loc='upper left')\n",
    "\n",
    "    return ax\n",
    "    \n",
    "def plotObjSpace(x,y,z,colorCode,savePlt=False):\n",
    "    # Create a 2D scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))    \n",
    "    \n",
    "    # Create a colormap that maps 1 to green and 0 to red\n",
    "    colors = np.select(\n",
    "    [z == 1, (z >= 0.5) & (z < 1)],\n",
    "    [colorCode[0], colorCode[1]],\n",
    "    default= colorCode[2]\n",
    "    )\n",
    "\n",
    "    # Create the scatter plot\n",
    "    plt.scatter(x, y, c=colors, edgecolors=\"w\", marker='s', linewidth=1)\n",
    "    \n",
    "    fntSize = 28\n",
    "    box_legend_loc = (0.5,-0.5)\n",
    "    legend_loc = 'lower center'\n",
    "    # Labels\n",
    "    plt.xlabel('Radii 1',fontsize=fntSize)\n",
    "    plt.ylabel(' ',fontsize=fntSize)\n",
    "    if compressionRatio == 0.1:\n",
    "        plt.ylabel('Radii 2',fontsize=fntSize)\n",
    "    \n",
    "    # Calculate rates\n",
    "    total = len(z)\n",
    "    success_rate = np.sum(z == 1) * 100 / total\n",
    "    partial_rate = np.sum((z >= 0.5) & (z < 1)) * 100 / total\n",
    "    failure_rate = np.sum(z < 0.5) * 100 / total\n",
    "    # Format rates to 2 significant digits\n",
    "    formatted_success = \"{:.2f}%\".format(success_rate)\n",
    "    formatted_partial = \"{:.2f}%\".format(partial_rate)\n",
    "    formatted_failure = \"{:.2f}%\".format(failure_rate)\n",
    "    \n",
    "    title_str = (\n",
    "    f\"Compression {int(compressionRatio*100)}%\\n\"\n",
    "    f\"Success: {formatted_success}\\n\"\n",
    "    f\"Partial success: {formatted_partial}\\n\"\n",
    "    f\"Failure: {formatted_failure}\"\n",
    "    )\n",
    "    plt.title(title_str, fontsize=fntSize)\n",
    "    ax.set_box_aspect(1)\n",
    "    ax.xaxis.set_tick_params(labelsize=fntSize)\n",
    "    ax.yaxis.set_tick_params(labelsize=fntSize)\n",
    "    # Create legend patches without the rates\n",
    "    success_patch = mpatches.Patch(color=colorCode[0], label='Success')\n",
    "    partial_patch = mpatches.Patch(color=colorCode[1], label='Partial success')\n",
    "    failed_patch = mpatches.Patch(color=colorCode[2], label='Failure')\n",
    "    \n",
    "   \n",
    "    if compressionRatio == 0.2:\n",
    "        success_patch = mpatches.Patch(color=colorCode[0], label='Success')\n",
    "        partial_patch = mpatches.Patch(color=colorCode[1], label='Partial success')\n",
    "        failed_patch = mpatches.Patch(color=colorCode[2], label='Failure')\n",
    "    else:\n",
    "        success_patch = mpatches.Patch(color='w', label='')\n",
    "        partial_patch = mpatches.Patch(color='w', label='')\n",
    "        failed_patch = mpatches.Patch(color='w', label='')\n",
    "        \n",
    "    # Add the legend to the plot    \n",
    "    plt.legend(handles=[success_patch,partial_patch,failed_patch], loc=legend_loc, \n",
    "    bbox_to_anchor=box_legend_loc, borderaxespad=0., fontsize=fntSize+4,frameon=False)  \n",
    "        \n",
    "    if savePlt:\n",
    "        savePath = os.path.realpath(os.path.join(sys.path[0],'../ObjSpacePlotC'+str(int(compressionRatio*100))+'.png'))\n",
    "        # Save the figure\n",
    "        plt.savefig(savePath, dpi=600, bbox_inches='tight')\n",
    "    # Show plot\n",
    "    plt.show()\n",
    " \n",
    "if p==2:\n",
    "    colorCode = ['#2ca02c', '#ff7f0e', '#d62728']\n",
    "    lbls = [\"Success\",\"Partial success\",\"Failure\"] # use abaqus 50% data for best curve to show diff between success and partial success\n",
    "    \n",
    "    plotObjSpace(R[:,0].reshape(-1),R[:,1].reshape(-1),analysisState.reshape(-1),\n",
    "                colorCode,savePlt=False) # green, orange, red\n",
    "\n",
    "    TotalDataSum = dataInput[:,2::].sum(axis=1)\n",
    "    \n",
    "    n1 = np.where(TotalDataSum == 11)[0][400]\n",
    "    n2 = np.where(TotalDataSum == 8)[0][30]\n",
    "    n3 = np.where(TotalDataSum == 4)[0][6]\n",
    "    print(n1,n2,n3)\n",
    "    \n",
    "    # n1,n2,n3 = 10,15,20\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111)  # Add a subplot to the figure\n",
    "    ax = plotFDcurves(ax, dataInput[n1:n1+1,:], dataOutput[n1:n1+1,:], lbls[0], strAdd='', colorshape={'color': colorCode[0], 'marker': 's'},addLabel=True)\n",
    "    ax = plotFDcurves(ax, dataInput[n2:n2+1,:], dataOutput[n2:n2+1,:], lbls[1], strAdd='', colorshape={'color': colorCode[1], 'marker': 'o'},addLabel=False)\n",
    "    ax = plotFDcurves(ax, dataInput[n3:n3+1,:], dataOutput[n3:n3+1,:], lbls[2], strAdd='', colorshape={'color': colorCode[2], 'marker': '^'},addLabel=False)\n",
    "\n",
    "\n",
    "lbls = [\"Training_set\",\"Validation_set\"]\n",
    "n1,n2 = 0,-1\n",
    "plotAllFDcurves(inputs_train[n1:n2,:],targets_train[n1:n2,:],inputs_test[n1:n2,:],targets_test[n1:n2,:],lbls,strAdd= '')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs_train_tensor  = torch.tensor(inputs_train, dtype=torch.float32)\n",
    "targets_train_tensor = torch.tensor(targets_train, dtype=torch.float32)\n",
    "inputs_test_tensor   = torch.tensor(inputs_test, dtype=torch.float32)\n",
    "targets_test_tensor  = torch.tensor(targets_test, dtype=torch.float32)\n",
    "\n",
    "# Create TensorDatasets (separately for train and test)\n",
    "train_dataset    = TensorDataset(inputs_train_tensor, targets_train_tensor)\n",
    "test_dataset     = TensorDataset(inputs_test_tensor, targets_test_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size_train = int(len(targets_train_tensor)/1) # You can adjust this for training\n",
    "batch_size_test  = int(len(targets_test_tensor)) # For full test set evaluation at the end\n",
    "train_loader     = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=False)\n",
    "test_loader      = DataLoader(test_dataset, batch_size=batch_size_test, shuffle=False)  # No need to shuffle test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnSettings = {'inputDim': inputSize,\n",
    "        'outputDim' : 6, #7 for F\n",
    "        'numLayers': 2, \n",
    "        'numNeuronsPerLyr': 80,\n",
    "        'curve':'spline',\n",
    "        'dropout':0.5, \n",
    "        'bottleneck_factor':1.0}\n",
    "\n",
    "print(f\"Input Var is R and of size {inputSize}\")\n",
    "NNmodel = NeuralNet(nnSettings,useCPU = False)\n",
    "print(f\"Total number of weights in the model: {NNmodel.total_weights}\")\n",
    "print(f\"Total number of biases in the model: {NNmodel.total_biases}\")\n",
    "NNmodel.train_model(train_loader,test_loader,num_epochs=5000,tol=1e-12,prntNum=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Saving the model:\n",
    "# torch.save(NNmodel, SaveLoc+'SurrogateModel.pth')  # Saves the entire model object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mae, avg_rmse,r2,maxV_indexT,minV_indexT = NNmodel.evaluate_NN(train_loader)   # Return both MAE and RMSE\n",
    "print(\"Result on the training set\")\n",
    "print(f\"MAE {avg_mae:.4f} , RMSE {avg_rmse:.4f}, and R_squared {r2:.4f}\")\n",
    "print(f\"Max abs sum error value {maxV_indexT.values.cpu()} ,\\n and Index {maxV_indexT.indices.cpu()}\\n\")\n",
    "avg_mae, avg_rmse,r2,maxV_index,minV_index = NNmodel.evaluate_NN(test_loader)   # Return both MAE and RMSE\n",
    "print(\"Result on the test set\")\n",
    "print(f\"MAE {avg_mae:.4f} , RMSE {avg_rmse:.4f}, and R_squared {r2:.4f}\")\n",
    "print(f\"Max abs sum error value {maxV_index.values.cpu()} ,\\n and Index {maxV_index.indices.cpu()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTrain,_ = NNmodel.predict_out(inputs_train)\n",
    "predTest,_ = NNmodel.predict_out(inputs_test)\n",
    "inputs_train2, inputs_test2 = inputs_train.copy(),inputs_test.copy()\n",
    "inputs_train2[:,2::] = 1\n",
    "inputs_test2[:,2::] = 1\n",
    "plotAllFDcurves(inputs_train2,predTrain,inputs_test2,predTest,strAdd= 'NN Prediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotNNFDcurve(inputs,target,arrayN,titleStrAdd,pltCP = False,savePath = None):\n",
    "    print(inputs.shape)\n",
    "    for num1 in arrayN:\n",
    "        num2 = num1+1\n",
    "        xyU = inputs[num1:num2,:]\n",
    "        print(xyU,inputs[num1,:])\n",
    "        u = np.linspace(0,1,2*len(xyU[0,2::]))\n",
    "        pred,CP = NNmodel.predict_out(xyU,u)#.reshape(-1)\n",
    "        actu = target[num1:num2,:].reshape(-1)\n",
    "        print(f\"Rad values: {xyU},\\n\")\n",
    "        # print(f\"Prediction: {Fpred},\\n Actual: {Factu}\")\n",
    "    \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        uu = np.linspace(0,1,len(actu))\n",
    "        nn = int(xyU[0,-len(actu)::].sum())\n",
    "        plt.plot(uu[0:nn],actu[0:nn],'r--^',label='Abaqus data',markersize=15,linewidth=3)\n",
    "        plt.plot(u,pred.reshape(-1),'b-',label=' Surrogate model prediction',linewidth=3)\n",
    "        \n",
    "        if pltCP:\n",
    "            CP = CP.reshape(-1)\n",
    "            n = len(CP)\n",
    "            p = 2 # hard coded to degree 2\n",
    "            e = np.linspace(0, 1, n - p + 1)\n",
    "            u = np.linspace(0, 1, n - p + 2)\n",
    "            u[1:-1] = e[:-1] + np.diff(e) / 2\n",
    "            plt.plot(u,CP,'m--s',label='NN B-Spline control points',markersize=8)\n",
    "\n",
    "        \n",
    "        # # Labels\n",
    "        plt.ylabel('Force in N',fontsize=16)\n",
    "        plt.xlabel('Normalized displacement',fontsize=16)\n",
    "        # plt.ylim(None,1.0)\n",
    "        \n",
    "       \n",
    "        maxF =  np.max(np.concatenate((actu.reshape(-1), pred.reshape(-1)))) * 1.5\n",
    "        plt.ylim([None, maxF])\n",
    "        \n",
    "        # Title\n",
    "        # abs_force_diff = np.abs(pred*xyU[0,-len(actu)::] - actu*xyU[0,-len(actu)::]).mean()\n",
    "        # titleStr = f'Force Displacement curve on {titleStrAdd} data {num1}\\n abs force diff = {abs_force_diff:.2f}'\n",
    "        # plt.title(titleStr,fontsize=18)\n",
    "        plt.legend(fontsize=16,loc='upper left')\n",
    "        if savePath is not None:\n",
    "           plt.savefig(savePath, dpi=600, bbox_inches='tight')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "all_inputs = []\n",
    "all_targets = []\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    all_inputs.append(inputs)\n",
    "    all_targets.append(targets)\n",
    "    \n",
    "inputs_train = torch.cat(all_inputs, dim=0).detach().cpu().numpy()\n",
    "targets_train = torch.cat(all_targets, dim=0).detach().cpu().numpy()\n",
    "    \n",
    "print(\"Number of train data\", inputs_train.shape)\n",
    "num1 = maxV_indexT.indices.cpu().numpy()\n",
    "\n",
    "# plotNNFDcurve(inputs_train,targets_train,maxV_indexT.indices.cpu().numpy(),'trained',pltCP = True)\n",
    "\n",
    "# plotNNFDcurve(inputs_train,targets_train,minV_indexT.indices.cpu().numpy(),'trained')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "all_targets = []\n",
    "\n",
    "for inputs, targets in test_loader:\n",
    "    all_inputs.append(inputs)\n",
    "    all_targets.append(targets)\n",
    "    \n",
    "inputs_test = torch.cat(all_inputs, dim=0).detach().cpu().numpy()\n",
    "targets_test = torch.cat(all_targets, dim=0).detach().cpu().numpy()\n",
    "\n",
    "print(\"Number of test data\", inputs_test.shape)\n",
    "# plotNNFDcurve(inputs_test,targets_test,maxV_index.indices.cpu().numpy(),'validation')\n",
    "# plotNNFDcurve(inputs_test,targets_test,minV_index.indices.cpu().numpy(),'validation')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num = 100\n",
    "np.random.seed(32)\n",
    "random_array = np.sort(np.random.randint(0,NNinputDiv.shape[0],size=5))\n",
    "print(random_array,NNinputDiv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plotNNFDcurve(NNinputDiv,NNoutputDiv,np.concatenate(([num], random_array)),'Failed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array = np.sort(np.random.randint(0,len(inputs_test[:,0]),size=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plotNNFDcurve(inputs_train,targets_train,random_array,'trained random',pltCP = True)\n",
    "# plotNNFDcurve(inputs_test,targets_test,random_array,'validation random',pltCP = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to show the CP and surrogate model and data\n",
    "if p==2:\n",
    "    max_in_target_data = np.max(targets_train,axis=1)\n",
    "     \n",
    "    inputs_train_new = inputs_train[(max_in_target_data > 2.0) , :]\n",
    "    targets_train_new = targets_train[(max_in_target_data > 2.0) , :]\n",
    "    \n",
    "    TotalDataSum = inputs_train_new[:,2::].sum(axis=1)\n",
    "    successN = np.where(TotalDataSum == 11)[0][12] #12 is close used for part1 \n",
    "    print(successN.shape)\n",
    "    plotNNFDcurve(inputs_train_new[successN,:].reshape(1,-1),targets_train_new[successN,:].reshape(1,-1),\n",
    "                    np.array([0]),'trained',pltCP=True,savePath='SurrNdata.png')\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to show surrogate model and data on test for full and partial success\n",
    "if p==2:\n",
    "    max_in_target_data = np.max(targets_test,axis=1)\n",
    "    \n",
    "    inputs_test_new = inputs_test[(max_in_target_data > 1.5) , :]\n",
    "    targets_test_new = targets_test[(max_in_target_data > 1.5) , :]\n",
    "    \n",
    "    TotalDataSum = inputs_test_new[:,2::].sum(axis=1)\n",
    "    successN = np.where(TotalDataSum == 11)[0][5] #5\n",
    "    print(\"--\",successN.shape)\n",
    "    plotNNFDcurve(inputs_test_new[successN,:].reshape(1,-1),targets_test_new[successN,:].reshape(1,-1),\n",
    "                    np.array([0]),'trained',pltCP=False,savePath='SurrValidatePredFull.png')\n",
    "                    \n",
    "    # find the half success \n",
    "    successN = np.where((TotalDataSum == 7) & (targets_test_new[:, 6] >= 5.0) & (targets_test_new[:, 6] <= 6.0))[0][1] #1\n",
    "    print(\"--\",successN.shape)\n",
    "    plotNNFDcurve(inputs_test_new[successN,:].reshape(1,-1),targets_test_new[successN,:].reshape(1,-1),\n",
    "                    np.array([0]),'trained',pltCP=False,savePath='SurrValidatePredPartial.png')\n",
    "    \n",
    "    ## special for failure\n",
    "    max_in_target_data = np.max(dataOutput,axis=1)\n",
    "    \n",
    "    inputs_test_new = dataInput[(max_in_target_data > 1.5) , :]\n",
    "    targets_test_new = dataOutput[(max_in_target_data > 1.5) , :]\n",
    "    \n",
    "    TotalDataSum = inputs_test_new[:,2::].sum(axis=1)\n",
    "    \n",
    "    # find the failure  \n",
    "    successN = np.where((TotalDataSum == 5))[0][10] #10\n",
    "    print(\"--\",successN.shape)\n",
    "    plotNNFDcurve(inputs_test_new[successN,:].reshape(1,-1),targets_test_new[successN,:].reshape(1,-1),\n",
    "    np.array([0]),'trained',pltCP=False,savePath='SurrValidatePredFailure.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workPyTcuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
